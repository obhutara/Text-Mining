{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How to Compare LDA Models\n",
    "=========================\n",
    "\n",
    "Demonstrates how you can compare a topic model with itself or other models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_number = 2\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, clean up the 20 Newsgroups dataset. We will use it to fit LDA.\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-28 06:48:17,664 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-11-28 06:48:20,611 : INFO : adding document #10000 to Dictionary(95280 unique tokens: ['addit', 'anyon', 'bodi', 'bricklin', 'brought']...)\n",
      "2019-11-28 06:48:20,945 : INFO : built Dictionary(105671 unique tokens: ['addit', 'anyon', 'bodi', 'bricklin', 'brought']...) from 11314 documents (total 1922370 corpus positions)\n",
      "2019-11-28 06:48:21,069 : INFO : discarding 87282 tokens: [('bricklin', 4), ('edu', 7393), ('host', 4848), ('know', 3533), ('lerxst', 2), ('line', 11282), ('nntp', 4777), ('organ', 10894), ('post', 5860), ('subject', 11314)]...\n",
      "2019-11-28 06:48:21,070 : INFO : keeping 18389 tokens which were in no less than 5 and no more than 3394 (=30.0%) documents\n",
      "2019-11-28 06:48:21,111 : INFO : resulting dictionary: Dictionary(18389 unique tokens: ['addit', 'anyon', 'bodi', 'brought', 'bumper']...)\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "newsgroups = fetch_20newsgroups()\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\s+', gaps=True)\n",
    "stemmer = PorterStemmer()\n",
    "translate_tab = {ord(p): u\" \" for p in punctuation}\n",
    "\n",
    "def text2tokens(raw_text):\n",
    "    \"\"\"Convert a raw text to a list of stemmed tokens.\"\"\"\n",
    "    clean_text = raw_text.lower().translate(translate_tab)\n",
    "    tokens = [token.strip() for token in tokenizer.tokenize(clean_text)]\n",
    "    tokens = [token for token in tokens if token not in eng_stopwords]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return [token for token in stemmed_tokens if len(token) > 2]  # skip short tokens\n",
    "\n",
    "dataset = [text2tokens(txt) for txt in newsgroups['data']]  # convert a documents to list of tokens\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary(documents=dataset, prune_at=None)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.3, keep_n=None)  # use Dictionary to remove un-relevant tokens\n",
    "dictionary.compactify()\n",
    "\n",
    "d2b_dataset = [dictionary.doc2bow(doc) for doc in dataset]  # convert list of tokens to bag of word representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, fit two LDA models.\n",
    "---------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-28 06:48:22,497 : INFO : using symmetric alpha at 0.06666666666666667\n",
      "2019-11-28 06:48:22,500 : INFO : using symmetric eta at 0.06666666666666667\n",
      "2019-11-28 06:48:22,506 : INFO : using serial LDA version on this node\n",
      "2019-11-28 06:48:22,549 : INFO : running batch LDA training, 15 topics, 10 passes over the supplied corpus of 11314 documents, updating every 11314 documents, evaluating every ~0 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-11-28 06:48:22,550 : INFO : training LDA model using 4 processes\n",
      "2019-11-28 06:48:22,610 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/11314, outstanding queue size 1\n",
      "2019-11-28 06:48:22,752 : INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/11314, outstanding queue size 2\n",
      "2019-11-28 06:48:22,754 : INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/11314, outstanding queue size 3\n",
      "2019-11-28 06:48:22,756 : INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/11314, outstanding queue size 4\n",
      "2019-11-28 06:48:22,758 : INFO : PROGRESS: pass 0, dispatched chunk #4 = documents up to #10000/11314, outstanding queue size 5\n",
      "2019-11-28 06:48:22,759 : INFO : PROGRESS: pass 0, dispatched chunk #5 = documents up to #11314/11314, outstanding queue size 6\n",
      "2019-11-28 06:48:44,407 : INFO : topic #2 (0.067): 0.005*\"peopl\" + 0.003*\"way\" + 0.003*\"good\" + 0.003*\"new\" + 0.003*\"comput\" + 0.003*\"work\" + 0.003*\"system\" + 0.003*\"think\" + 0.003*\"time\" + 0.003*\"want\"\n",
      "2019-11-28 06:48:44,408 : INFO : topic #9 (0.067): 0.003*\"peopl\" + 0.003*\"max\" + 0.003*\"time\" + 0.003*\"think\" + 0.003*\"make\" + 0.003*\"armenian\" + 0.003*\"also\" + 0.003*\"say\" + 0.002*\"system\" + 0.002*\"work\"\n",
      "2019-11-28 06:48:44,409 : INFO : topic #11 (0.067): 0.005*\"new\" + 0.004*\"think\" + 0.003*\"peopl\" + 0.003*\"state\" + 0.003*\"say\" + 0.003*\"file\" + 0.003*\"want\" + 0.003*\"look\" + 0.003*\"work\" + 0.003*\"good\"\n",
      "2019-11-28 06:48:44,411 : INFO : topic #7 (0.067): 0.004*\"say\" + 0.004*\"window\" + 0.004*\"drive\" + 0.003*\"year\" + 0.003*\"scsi\" + 0.003*\"also\" + 0.003*\"max\" + 0.003*\"peopl\" + 0.003*\"way\" + 0.003*\"need\"\n",
      "2019-11-28 06:48:44,412 : INFO : topic #6 (0.067): 0.005*\"window\" + 0.004*\"think\" + 0.004*\"peopl\" + 0.003*\"say\" + 0.003*\"also\" + 0.003*\"work\" + 0.003*\"time\" + 0.003*\"could\" + 0.003*\"state\" + 0.003*\"year\"\n",
      "2019-11-28 06:48:44,414 : INFO : topic diff=2.847699, rho=1.000000\n",
      "2019-11-28 06:48:44,415 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #2000/11314, outstanding queue size 1\n",
      "2019-11-28 06:48:44,499 : INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #4000/11314, outstanding queue size 2\n",
      "2019-11-28 06:48:44,651 : INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #6000/11314, outstanding queue size 3\n",
      "2019-11-28 06:48:44,652 : INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #8000/11314, outstanding queue size 4\n",
      "2019-11-28 06:48:44,655 : INFO : PROGRESS: pass 1, dispatched chunk #4 = documents up to #10000/11314, outstanding queue size 5\n",
      "2019-11-28 06:48:44,657 : INFO : PROGRESS: pass 1, dispatched chunk #5 = documents up to #11314/11314, outstanding queue size 6\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "num_topics = 15\n",
    "\n",
    "lda_fst = LdaMulticore(\n",
    "    corpus=d2b_dataset, num_topics=num_topics, id2word=dictionary,\n",
    "    workers=4, eval_every=None, passes=10, batch=True\n",
    ")\n",
    "\n",
    "lda_snd = LdaMulticore(\n",
    "    corpus=d2b_dataset, num_topics=num_topics, id2word=dictionary,\n",
    "    workers=4, eval_every=None, passes=20, batch=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to visualize, yay!\n",
    "-----------------------\n",
    "\n",
    "We use two slightly different visualization methods depending on how you're running this tutorial.\n",
    "If you're running via a Jupyter notebook, then you'll get a nice interactive Plotly heatmap.\n",
    "If you're viewing the static version of the page, you'll get a similar matplotlib heatmap, but it won't be interactive.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference_plotly(mdiff, title=\"\", annotation=None):\n",
    "    \"\"\"Plot the difference between models.\n",
    "\n",
    "    Uses plotly as the backend.\"\"\"\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.offline as py\n",
    "\n",
    "    annotation_html = None\n",
    "    if annotation is not None:\n",
    "        annotation_html = [\n",
    "            [\n",
    "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "                for (int_tokens, diff_tokens) in row\n",
    "            ]\n",
    "            for row in annotation\n",
    "        ]\n",
    "\n",
    "    data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
    "    layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
    "    py.iplot(dict(data=[data], layout=layout))\n",
    "\n",
    "\n",
    "def plot_difference_matplotlib(mdiff, title=\"\", annotation=None):\n",
    "    \"\"\"Helper function to plot difference between models.\n",
    "\n",
    "    Uses matplotlib as the backend.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(data)\n",
    "\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "    import plotly.offline as py\n",
    "except Exception:\n",
    "    #\n",
    "    # Fall back to matplotlib if we're not in a notebook, or if plotly is\n",
    "    # unavailable for whatever reason.\n",
    "    #\n",
    "    plot_difference = plot_difference_matplotlib\n",
    "else:\n",
    "    py.init_notebook_mode()\n",
    "    plot_difference = plot_difference_plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim can help you visualise the differences between topics. For this purpose, you can use the ``diff()`` method of LdaModel.\n",
    "\n",
    "``diff()`` returns a matrix with distances **mdiff** and a matrix with annotations **annotation**. Read the docstring for more detailed info.\n",
    "\n",
    "In each **mdiff[i][j]** cell you'll find a distance between **topic_i** from the first model and **topic_j** from the second model.\n",
    "\n",
    "In each **annotation[i][j]** cell you'll find **[tokens from intersection, tokens from difference** between **topic_i** from first model and **topic_j** from the second model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LdaMulticore.diff.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1: How topics within ONE model correlate with each other.\n",
    "--------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short description:\n",
    "\n",
    "* x-axis - topic;\n",
    "\n",
    "* y-axis - topic;\n",
    "\n",
    ".. role:: raw-html-m2r(raw)\n",
    "   :format: html\n",
    "\n",
    "* :raw-html-m2r:`<span style=\"color:red\">almost red cell</span>` - strongly decorrelated topics;\n",
    "\n",
    ".. role:: raw-html-m2r(raw)\n",
    "   :format: html\n",
    "\n",
    "* :raw-html-m2r:`<span style=\"color:blue\">almost blue cell</span>` - strongly correlated topics.\n",
    "\n",
    "In an ideal world, we would like to see different topics decorrelated between themselves. In this case, our matrix would look like this:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mdiff = np.ones((num_topics, num_topics))\n",
    "np.fill_diagonal(mdiff, 0.)\n",
    "plot_difference(mdiff, title=\"Topic difference (one model) in ideal world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in real life, not everything is so good, and the matrix looks different.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short description (interactive annotations only):\n",
    "\n",
    "\n",
    "\n",
    "* ``+++ make, world, well`` - words from the intersection of topics = present in both topics;\n",
    "\n",
    "\n",
    "\n",
    "* ``--- money, day, still`` - words from the symmetric difference of topics = present in one topic but not the other.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdiff, annotation = lda_fst.diff(lda_fst, distance='jaccard', num_words=50)\n",
    "plot_difference(mdiff, title=\"Topic difference (one model) [jaccard distance]\", annotation=annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare a model with itself, you want to see as many red elements as possible (except diagonal). With this picture, you can look at the not very red elements and understand which topics in the model are very similar and why (you can read annotation if you move your pointer to cell).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Jaccard is stable and robust distance function, but this function not enough sensitive for some purposes. Let's try to use Hellinger distance now.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdiff, annotation = lda_fst.diff(lda_fst, distance='hellinger', num_words=50)\n",
    "plot_difference(mdiff, title=\"Topic difference (one model)[hellinger distance]\", annotation=annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that everything has become worse, but remember that everything depends on the task.\n",
    "\n",
    "\n",
    "\n",
    "You need to choose the function with which your personal point of view about topics similarity and your task (from my experience, Jaccard is fine).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2: How topics from DIFFERENT models correlate with each other.\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we want to look at the patterns between two different models and compare them.\n",
    "\n",
    "You can do this by constructing a matrix with the difference.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdiff, annotation = lda_fst.diff(lda_snd, distance='jaccard', num_words=50)\n",
    "plot_difference(mdiff, title=\"Topic difference (two models)[jaccard distance]\", annotation=annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this matrix, you can find similar and different topics (and relevant tokens which describe the intersection and difference).\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
